\chapter{Introduction}
\label{chapter:intro}
\emph{Automatic Speech Recognition} (ASR) is the process of converting speech into text. ASR is used in a wide range of applications like digital assistants,  captioning audio conversations, etc. ASR systems convert digital speech audio to text transcriptions using pattern matching techniques. Research in this field has become very dynamic in the previous decade with the usage of deep neural networks for ASR. \emph{Deep neural networks} (DNN) are a faction of machine learning models, which consist of multiple layers of neurons and learn to provide the required output. Applying deep neural networks for ASR requires speech audio data which also have been transcribed. This is then fed to the deep neural networks to help it to learn new and unseen audio data, and this process is called model training. State-of-the-art ASR systems that use deep learning require large amounts of training data. 

Increasing the data used for training deep neural network models have previously led to substantial increases in accuracy of these models. Moreover, considering the decreasing costs of data storage and network costs, scaling up training to higher and higher amounts of training data has become an interesting trend over the recent years. Popular cloud-based solutions offered by big enterprises use the vast amount of resources available to them to train deep learning models that are able to process most of the clear speech audio with high levels of accuracy. (TODO : add citation?). These large scale experiments are harder to conduct for smaller companies and for academic institutions, because of the need for high amounts of storage and processing power for the process of training, which are not easily available. Hence, there is a need for optimising the training process to reduce the storage footprint, processing power, and resources required to train large-scale deep learning models.

Large scale training jobs generally use distributed training, which means that multiple processing units are used with the data present in a network location. This introduces new problems like optimising input/output read performance and managing local storage, etc. These are the problems with respect to infrastructure and engineering related domains. Apart from these, there are also research based problems which include convergence issues when using stochastic gradient descent in a distributed setup of training.  



\section{Problem statement}




\section{Structure of the Thesis}
\label{section:structure} 


